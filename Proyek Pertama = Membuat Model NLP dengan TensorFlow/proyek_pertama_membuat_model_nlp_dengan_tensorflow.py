# -*- coding: utf-8 -*-
"""Proyek Pertama : Membuat Model NLP dengan TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14_jIZowOmfjKzwsnJqnAQt7WGz3V8BRh

Herliana Nur Ekawati

NIM 11201038

Grup M07

Sumber dataset: https://www.kaggle.com/datasets/gregorut/videogamesales

Impor library pandas dan ubah dataset menjadi dataframe. Kemudian munculkan kolom hanya Name, Genre, dan Publisher sebagai atribut untuk dilatih
"""

import pandas as pd
df = pd.read_csv('vgsales.csv')
df = df[['Name', 'Genre', 'Publisher']]

"""Untuk menampilkan sampel"""

df

"""Melakukan proses one-hot-encoding"""

category = pd.get_dummies(df.Genre)
df_baru = pd.concat([df, category], axis=1)
df_baru = df_baru.drop(columns='Genre')
df_baru

"""Mengubah nilai-nilai dataframe ke dalam tipe data numpy array"""

name = df_baru['Name'].values
label = df_baru[['Action', 'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', 'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy']].values

"""Bagi data untuk training dan untuk testing dengan data validasi 20%"""

from sklearn.model_selection import train_test_split
name_latih, name_test, label_latih, label_test = train_test_split(name, label, test_size=0.2)

"""Mengubah setiap kata pada dataset ke dalam bilangan numerik dengan Fungsi Tokenizer"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(name_latih)
tokenizer.fit_on_texts(name_test)

sekuens_latih = tokenizer.texts_to_sequences(name_latih)
sekuens_test = tokenizer.texts_to_sequences(name_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

"""Embedding, LSTM"""

from tensorflow.python import metrics
import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=5000, output_dim=128),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(12, activation='softmax')
])
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Callback"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.97):
      print("Training dihentikan karena akurasi telah mencapai 97%")
      self.model.stop_training = True

callbacks = myCallback()

"""Melatih model"""

num_epochs = 25
history = model.fit(padded_latih, 
                    label_latih, 
                    epochs=num_epochs, 
                    validation_data=(padded_test, label_test),
                    verbose=2,
                    callbacks=[callbacks])

"""Plot loss dan akurasi pada saat training dan validation"""

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.title('Akurasi Training dan Validation')
plt.plot(epochs, acc, 'r', label='Training')
plt.plot(epochs, val_acc, 'b', label='Validation')
plt.legend(loc=0)
plt.figure()
plt.show()

epochs = range(len(loss))

plt.title('Akurasi Loss dan Validation Loss')
plt.plot(epochs, loss, 'g', label='Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.legend(loc=0)
plt.figure()
plt.show()